<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Performance :: Hazelcast Documentation</title>
    <link rel="canonical" href="https://JakeSCahill.github.io/hazelcast/4.1/develop/performance.html">
    <meta name="generator" content="Antora 2.3.4">
    <link rel="stylesheet" href="../../../_/css/site.css">
<link rel="stylesheet" href="../../../_/css/search.css">
    <script async src="https://www.googletagmanager.com/gtag/js?id=GTM-M267KFN"></script>
    <script>function gtag(){dataLayer.push(arguments)};window.dataLayer=window.dataLayer||[];gtag('js',new Date());gtag('config','GTM-M267KFN')</script>
  </head>
  <body class="article">
<header class="header" role="banner">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://JakeSCahill.github.io">Hazelcast Documentation</a>
        <div class="navbar-item">
          <input id="search-input" type="text" placeholder="Search docs">
        </div>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="#">Home</a>
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">Products</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="#">Hazelcast IMDG</a>
            <a class="navbar-item" href="#">Hazelcast Jet</a>
            <a class="navbar-item" href="#">Hazelcast Cloud</a>
          </div>
        </div>
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">Use cases</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="#">Service A</a>
            <a class="navbar-item" href="#">Service B</a>
            <a class="navbar-item" href="#">Service C</a>
          </div>
        </div>
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">Resources</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="#">Demos</a>
            <a class="navbar-item" href="#">GitHub</a>
            <a class="navbar-item" href="#">Community</a>
            <a class="navbar-item" href="#">Blog</a>
          </div>
        </div>
        <div class="navbar-item">
          <span class="control">
            <a class="button is-primary" href="#">Download</a>
          </span>
        </div>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="hazelcast" data-version="4.1">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../hazelcast_overview.html">Hazelcast IMDG</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../hazelcast_overview.html">Overview</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../get-started/getting_started.html">Get Started</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../get-started/glossary.html">Glossary</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="hazelcast_clients.html">Develop Solutions</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="jcache.html">JCache</a>
  </li>
  <li class="nav-item is-current-page" data-depth="2">
    <a class="nav-link" href="performance.html">Performance</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="serialization.html">Serialization</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="striim_cdc.html">Striim Hot Cache</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="transactions.html">Transactions</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="distributed_query.html">Distributed Query</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="distributed_sql.html">Distributed SQL</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="distributed_events.html">Distributed Events</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="distributed_computing.html">Distributed Computing</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../deploy/installing_upgrading.html">Deploy Clusters</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../deploy/starting_members_clients.html">Starting Members and Clients</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../deploy/setting_up_clusters.html">Setting Up Clusters</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../deploy/management.html">Management</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../deploy/security.html">Security</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../deploy/simulator.html">Hazelcast Simulator</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../deploy/wan.html">WAN Replication</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../deploy/network_partitioning.html">Network Partitioning</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../migrate/migration_guides.html">Migrate</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../troubleshoot/common_exception_types.html">Troubleshooting</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../reference/faq.html">Reference</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../reference/dds.html">Distributed data structures</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../reference/system_properties.html">System properties</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../reference/understanding_configuration.html">Configuration</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../reference/phone_homes.html">Phone homes</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../reference/hazelcast_plugins.html">Plugins</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../contribute/extending_hazelcast.html">Contribute</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../contribute/licenses.html">Licenses</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../contribute/revision_history.html">Documentation changes</a>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Hazelcast IMDG</span>
    <span class="version">4.1</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <span class="title">Hazelcast IMDG</span>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../hazelcast_overview.html">4.1</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../preface.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../hazelcast_overview.html">Hazelcast IMDG</a></li>
    <li><a href="hazelcast_clients.html">Develop Solutions</a></li>
    <li><a href="performance.html">Performance</a></li>
  </ul>
</nav>
  <div class="edit-this-page"><a class="git" href="https://github.com/JakeSCahill/docs-poc/edit/master/hazelcast-docs/modules/develop/pages/performance.adoc">Edit this Page</a></div>
  </div>
  <div class="content">
<article class="doc">
<h1 class="page">Performance</h1>
<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>This chapter provides information on the performance features of
Hazelcast including near cache, slow operations detector, back pressure and
data affinity. Moreover, the chapter describes the best performance practices for
Hazelcast deployed on Amazon EC2. It also describes the threading models for I/O, events, executors and operations.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_pipelining"><a class="anchor" href="#_pipelining"></a>Pipelining</h2>
<div class="sectionbody">
<div class="paragraph">
<p>With the pipelining, you can send multiple
requests in parallel using a single thread  and therefore can increase throughput.
As an example, suppose that the round trip time for a request/response
is 1 millisecond. If synchronous requests are used, e.g., <code>IMap.get()</code>, then the maximum throughput out of these requests from
a single thread is 1/001 = 1000 operations/second. One way to solve this problem is to introduce multithreading to make
the requests in parallel. For the same example, if we would use 2 threads, then the maximum throughput doubles from 1000
operations/second, to 2000 operations/second.</p>
</div>
<div class="paragraph">
<p>However, introducing threads for the sake of executing requests isn&#8217;t always convenient and doesn&#8217;t always lead to an optimal
performance; this is where the pipelining can be used. Instead of using multiple threads to have concurrent invocations,
you can use asynchronous method calls such as <code>IMap.getAsync()</code>. If you would use 2 asynchronous calls from a single thread,
then the maximum throughput is 2*(1/001) = 2000 operations/second. Therefore, to benefit from the pipelining, asynchronous calls need to
be made from a single thread. The pipelining is a convenience implementation to provide back pressure, i.e., controlling
the number of inflight operations, and it provides a convenient way to wait for all the results.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">Pipelining&lt;String&gt; pipelining = new Pipelining&lt;String&gt;(10);
for (long k = 0; k &lt; 100; k++) {
    int key = random.nextInt(keyDomain);
    pipelining.add(map.getAsync(key));
}
// wait for completion
List&lt;String&gt; results = pipelining.results();</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above example, we make 100 asynchronous <code>map.getAsync()</code> calls, but the maximum number of inflight calls is 10.</p>
</div>
<div class="paragraph">
<p>By increasing the depth of the pipelining, throughput can be increased. The pipelining has its own back pressure, you do not
need to enable the <a href="#back-pressure">back pressure</a> on the client or member to have this feature on the pipelining. However, if you have many
pipelines, you may still need to enable the client/member back pressure because it is possible to overwhelm the system
with requests in that situation. See the <a href="#back-pressure">Back Pressure section</a> to learn how to enable it on the client or member.</p>
</div>
<div class="paragraph">
<p>You can use the pipelining both on the clients and members. You do not need a special configuration, it works out-of-the-box.</p>
</div>
<div class="paragraph">
<p>The pipelining can be used for any asynchronous call. You can use it for IMap asynchronous get/put methods as well as for
ICache, IAtomicLong, etc. It cannot be used as a transaction mechanism though. So you cannot do some calls and throw away the pipeline and expect that
none of the requests are executed. If you want to use an atomic behavior, see the <a href="#transactions">Transactions chapter</a>.
The pipelining is just a performance optimization, not a mechanism for atomic behavior.</p>
</div>
<div class="paragraph">
<p>The pipelines are cheap and should frequently be replaced because they accumulate results. It is fine to have a few hundred or
even a few thousand calls being processed with the pipelining. However, all the responses to all requests are stored in the pipeline
as long as the pipeline is referenced. So if you want to process a huge number of requests, then every few hundred or few
thousand calls wait for the pipelining results and just create a new instance.</p>
</div>
<div class="paragraph">
<p>Note that the pipelines are not thread-safe. They must be used by a single thread.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_data_affinity"><a class="anchor" href="#_data_affinity"></a>Data Affinity</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Data affinity ensures that related entries exist on the same member. If related data is on the same member, operations can
be executed without the cost of extra network calls and extra wire data. This feature is provided by using the same partition keys for related data.</p>
</div>
<div class="sect2">
<h3 id="_partitionaware"><a class="anchor" href="#_partitionaware"></a>PartitionAware</h3>
<div class="paragraph">
<p><strong>Co-location of related data and computation</strong></p>
</div>
<div class="paragraph">
<p>Hazelcast has a standard way of finding out which member owns/manages each key object.
The following operations are routed to the same member, since all of them are operating based on the same key <code>"key1"</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">HazelcastInstance hazelcastInstance = Hazelcast.newHazelcastInstance();
Map mapA = hazelcastInstance.getMap( "mapA" );
Map mapB = hazelcastInstance.getMap( "mapB" );
Map mapC = hazelcastInstance.getMap( "mapC" );

// since map names are different, operation will be manipulating
// different entries, but the operation will take place on the
// same member since the keys ("key1") are the same
mapA.put( "key1", value );
mapB.get( "key1" );
mapC.remove( "key1" );

// lock operation will still execute on the same member
// of the cluster since the key ("key1") is same
hazelcastInstance.getLock( "key1" ).lock();

// distributed execution will execute the 'runnable' on the
// same member since "key1" is passed as the key.
hazelcastInstance.getExecutorService().executeOnKeyOwner( runnable, "key1" );</code></pre>
</div>
</div>
<div class="paragraph">
<p>When the keys are the same, entries are stored on the same member.
But we sometimes want to have related entries stored on the same member, such as a customer and his/her order entries.
We would have a customers map with customerId as the key and an orders map with orderId as the key.
Since customerId and orderId are different keys, a customer and
his/her orders may fall into different members in your cluster. So how can we have them stored on the same member?
We create an affinity between customer and orders. If we make them part of the same partition then
these entries will be co-located. We achieve this by making <code>orderKey</code> s <code>PartitionAware</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">final class OrderKey implements PartitionAware, Serializable {

    private final long orderId;
    private final long customerId;

    OrderKey(long orderId, long customerId) {
        this.orderId = orderId;
        this.customerId = customerId;
    }

    @Override
    public Object getPartitionKey() {
        return customerId;
    }

    @Override
    public String toString() {
        return "OrderKey{"
                + "orderId=" + orderId
                + ", customerId=" + customerId
                + '}';</code></pre>
</div>
</div>
<div class="paragraph">
<p>Notice that OrderKey implements <code>PartitionAware</code> and that <code>getPartitionKey()</code> returns the <code>customerId</code>.
These make sure that the <code>Customer</code> entry and its <code>Order</code>s are stored on the same member.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">HazelcastInstance hazelcastInstance = Hazelcast.newHazelcastInstance();
Map mapCustomers = hazelcastInstance.getMap( "customers" );
Map mapOrders = hazelcastInstance.getMap( "orders" );

// create the customer entry with customer id = 1
mapCustomers.put( 1, customer );

// now create the orders for this customer
mapOrders.put( new OrderKey( 21, 1 ), order );
mapOrders.put( new OrderKey( 22, 1 ), order );
mapOrders.put( new OrderKey( 23, 1 ), order );</code></pre>
</div>
</div>
<div class="paragraph">
<p>Assume that you have a customers map where <code>customerId</code> is the key and the customer object is the value.
You want to remove one of the customer orders and return the number of remaining orders.
Here is how you would normally do it.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">public static int removeOrder( long customerId, long orderId ) throws Exception {
    IMap&lt;Long, Customer&gt; mapCustomers = instance.getMap( "customers" );
    IMap mapOrders = hazelcastInstance.getMap( "orders" );

    mapCustomers.lock( customerId );
    mapOrders.remove( new OrderKey(orderId, customerId) );
    Set orders = orderMap.keySet(Predicates.equal( "customerId", customerId ));
    mapCustomers.unlock( customerId );

    return orders.size();
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>There are couple of things you should consider.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>There are four distributed operations there: lock, remove, keySet, unlock. Can you reduce
the number of distributed operations?</p>
</li>
<li>
<p>The customer object may not be that big, but can you not have to pass that object through the
wire? Think about a scenario where you set order count to the customer object for fast access, so you
should do a get and a put, and as a result, the customer object is passed through the wire twice.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Instead, why not move the computation over to the member (JVM) where your customer data resides.
Here is how you can do this with distributed executor service.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Send a <code>PartitionAware</code> <code>Callable</code> task.</p>
</li>
<li>
<p><code>Callable</code> does the deletion of the order right there and returns with the remaining
order count.</p>
</li>
<li>
<p>Upon completion of the <code>Callable</code> task, return the result (remaining order count). You
do not have to wait until the task is completed; since distributed executions are asynchronous,
you can do other things in the meantime.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Here is an example code.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">HazelcastInstance hazelcastInstance = Hazelcast.newHazelcastInstance();

    public int removeOrder(long customerId, long orderId) throws Exception {
        IExecutorService executorService = hazelcastInstance.getExecutorService("ExecutorService");

        OrderDeletionTask task = new OrderDeletionTask(customerId, orderId);
        Future&lt;Integer&gt; future = executorService.submit(task);
        int remainingOrders = future.get();

        return remainingOrders;
    }

    public static class OrderDeletionTask
            implements Callable&lt;Integer&gt;, PartitionAware, Serializable, HazelcastInstanceAware {

        private long orderId;
        private long customerId;
        private HazelcastInstance hazelcastInstance;

        public OrderDeletionTask() {
        }

        public OrderDeletionTask(long customerId, long orderId) {
            this.customerId = customerId;
            this.orderId = orderId;
        }

        @Override
        public Integer call() {
            IMap&lt;Long, Customer&gt; customerMap = hazelcastInstance.getMap("customers");
            IMap&lt;OrderKey, Order&gt; orderMap = hazelcastInstance.getMap("orders");

            customerMap.lock(customerId);

            Predicate predicate = Predicates.equal("customerId", customerId);
            Set&lt;OrderKey&gt; orderKeys = orderMap.localKeySet(predicate);
            int orderCount = orderKeys.size();
            for (OrderKey key : orderKeys) {
                if (key.orderId == orderId) {
                    orderCount--;
                    orderMap.delete(key);
                }
            }

            customerMap.unlock(customerId);

            return orderCount;
        }

        @Override
        public Object getPartitionKey() {
            return customerId;
        }

        @Override
        public void setHazelcastInstance(HazelcastInstance hazelcastInstance) {
            this.hazelcastInstance = hazelcastInstance;
        }
    }</code></pre>
</div>
</div>
<div class="paragraph">
<p>The following are the benefits of doing the same operation with distributed <code>ExecutorService</code> based on the key:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>only one distributed execution (<code>executorService.submit(task)</code>), instead of four</p>
</li>
<li>
<p>less data is sent over the wire</p>
</li>
<li>
<p>less lock duration, i.e., higher concurrency, for the <code>Customer</code> entry since
lock/update/unlock cycle is done locally (local to the customer data)</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_partitioningstrategy"><a class="anchor" href="#_partitioningstrategy"></a>PartitioningStrategy</h3>
<div class="paragraph">
<p>Another way of storing the related data on the same location is using/implementing
the class <code>PartitioningStrategy</code>. Normally (if no partitioning strategy is defined),
Hazelcast finds the partition of a key first by converting the object to binary and then by hashing this binary.
If a partitioning strategy is defined, Hazelcast injects the key to the strategy and
the strategy returns an object out of which the partition is calculated by hashing it.</p>
</div>
<div class="paragraph">
<p>Hazelcast offers the following out-of-the-box partitioning strategies:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>DefaultPartitioningStrategy</code>: Default strategy. It checks whether the key implements <code>PartitionAware</code>.
If it implements, the object is converted to binary and then hashed, to find the partition of the key.</p>
</li>
<li>
<p><code>StringPartitioningStrategy</code>: Works only for string keys. It uses the string after <code>@</code> character as the partition ID.
For example, if you have two keys <code>ordergroup1@region1</code> and <code>customergroup1@region1</code>,
both <code>ordergroup1</code> and <code>customergroup1</code> fall into the partition where <code>region1</code> is located.</p>
</li>
<li>
<p><code>StringAndPartitionAwarePartitioningStrategy</code>: Works as the combination of the above two strategies.
If the key implements <code>PartitionAware</code>, it works like the <code>DefaultPartitioningStrategy</code>.
If it is a string key, it works like the <code>StringPartitioningStrategy</code>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Following are the example configuration snippets. Note that these strategy configurations are <strong>per map</strong>.</p>
</div>
<div class="paragraph">
<p><strong>Declarative Configuration:</strong></p>
</div>
<div class="listingblock primary">
<div class="title">XML</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-xml hljs" data-lang="xml">&lt;hazelcast&gt;
    ...
    &lt;map name="name-of-the-map"&gt;
        &lt;partition-strategy&gt;
             com.hazelcast.partition.strategy.StringAndPartitionAwarePartitioningStrategy
        &lt;/partition-strategy&gt;
    &lt;/map&gt;
    ...
&lt;/hazelcast&gt;</code></pre>
</div>
</div>
<div class="listingblock secondary">
<div class="title">YAML</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yml hljs" data-lang="yml">hazelcast:
  map:
    name-of-the-map:
      partition-strategy: com.hazelcast.partition.strategy.StringAndPartitionAwarePartitioningStrategy</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Programmatic Configuration:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">Config config = new Config();
MapConfig mapConfig = config.getMapConfig("name-of-the-map");
PartitioningStrategyConfig psConfig = mapConfig.getPartitioningStrategyConfig();
psConfig.setPartitioningStrategyClass( "StringAndPartitionAwarePartitioningStrategy" );

// OR
psConfig.setPartitioningStrategy(YourCustomPartitioningStrategy);
...</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can also define your own partition strategy by implementing the class <code>PartitioningStrategy</code>.
To enable your implementation, add the full class name to your Hazelcast configuration using either
the declarative or programmatic approach, as exemplified above.</p>
</div>
<div class="paragraph">
<p>The examples above show how to define a partitioning strategy per map.
Note that all the members of your cluster must have the same
partitioning strategy configurations.</p>
</div>
<div class="paragraph">
<p>You can also change a global strategy which is applied to all the data structures in your cluster.
This can be done by defining the <code>hazelcast.partitioning.strategy.class</code> system property.
An example declarative way of configuring this property is shown below:</p>
</div>
<div class="listingblock primary">
<div class="title">XML</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-xml hljs" data-lang="xml">&lt;hazelcast&gt;
    ...
    &lt;properties&gt;
        &lt;property name="hazelcast.partitioning.strategy.class"&gt;
            com.hazelcast.partition.strategy.StringAndPartitionAwarePartitioningStrategy
        &lt;/property&gt;
    &lt;/properties&gt;
    ...
&lt;/hazelcast&gt;</code></pre>
</div>
</div>
<div class="listingblock secondary">
<div class="title">YAML</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yml hljs" data-lang="yml">hazelcast:
  properties:
    hazelcast.partitioning.strategy.class: com.hazelcast.partition.strategy.StringAndPartitionAwarePartitioningStrategy</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can specify the aforementioned out-of-the-box strategies or your custom
partitioning strategy.</p>
</div>
<div class="paragraph">
<p>You can also use other system property configuring options as explained in the
<a href="#configuring-with-system-properties">Configuring with System Properties section</a>.</p>
</div>
<div class="paragraph">
<p>The per map and global (cluster) partitioning strategies are supported on the member side.
Hazelcast IMDG Java clients only support the global strategy and it is configured
via the same system property used in the members (`hazelcast.partitioning.strategy.class `).</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_cpu_thread_affinity"><a class="anchor" href="#_cpu_thread_affinity"></a>CPU Thread Affinity</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Hazelcast offers configuring CPU threads so that you have a lot better control
on the latency and a better throughput. This configuration provides you
with the CPU thread affinity, where certain threads can have affinity for particular CPUs.</p>
</div>
<div class="paragraph">
<p>The following affinity configurations are available for a member:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>-Dhazelcast.io.input.thread.affinity=1-3
-Dhazelcast.io.output.thread.affinity=3-5
-Dhazelcast.operation.thread.affinity=7-10,13
-Dhazelcast.operation.response.thread.affinity=15,16</code></pre>
</div>
</div>
<div class="paragraph">
<p>The following affinity configurations are available for a client:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>-Dhazelcast.client.io.input.thread.affinity=1-4
-Dhazelcast.client.io.output.thread.affinity=5-8
-Dhazelcast.client.response.thread.affinity=7-9</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can set the CPU thread affinity properties shown above only on the command line.</p>
</div>
<div class="paragraph">
<p>Let&#8217;s have a look at how we define the values for the above configuration
properties:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Individual CPUs</strong>, e.g., <code>1,2,3</code>: This means there are going to be
three threads. The first thread runs on CPU 1, the second thread on CPU 2, and so on.</p>
</li>
<li>
<p><strong>CPU ranges</strong>, e.g., <code>1-3</code>: Shortcut syntax for <code>1,2,3</code>.</p>
</li>
<li>
<p><strong>Group</strong>, e.g., <code>[1-3]</code>: This configures three threads and each of
these threads can run on CPU 1, 2 and 3.</p>
</li>
<li>
<p><strong>Group with thread count</strong>, e.g., <code>[1-3]:2</code>: This configures two
threads and each of these two threads can run on CPU 1, 2 and 3.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>You can also combine those, e.g., <code>1,2,[5-7],[10,12,16]:2</code>.</p>
</div>
<div class="paragraph">
<p>Note that, the syntax for CPU thread affinity shown above not only determines
the mapping of CPUs to threads, it also determines the thread count.
If you use CPU thread affinity, e.g., <code>hazelcast.io.input.thread.affinity</code>,
then <code>hazelcast.io.input.thread.count</code> is ignored. See <a href="#io-threading">[io-threading]</a> for more
information on specifying explicit thread counts.</p>
</div>
<div class="paragraph">
<p>If you don&#8217;t configure affinity for a category of threads, it means they can run on any CPU.</p>
</div>
<div class="paragraph">
<p>Let&#8217;s look at an example. Assuming you have the <code>numactl</code> utility, run
the following command on your machine to see the mapping between the NUMA
nodes and threads:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>numactl --hardware</code></pre>
</div>
</div>
<div class="paragraph">
<p>An example output is shown below:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>available: 2 nodes (0-1)
node 0 cpus: 0 1 2 3 4 5 6 7 8 9 20 21 22 23 24 25 26 27 28 29
node 0 size: 393090 MB
node 0 free: 372729 MB
node 1 cpus: 10 11 12 13 14 15 16 17 18 19 30 31 32 33 34 35 36 37 38 39
node 1 size: 393216 MB
node 1 free: 343296 MB
node distances:
node   0   1
  0:  10  21
  1:  21  10</code></pre>
</div>
</div>
<div class="paragraph">
<p>If you want to configure 20 threads on NUMA node 0 and 20 threads on NUMA node 1,
and confine the threads to these NUMA nodes, you can use the following configuration:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>-Dhazelcast.operation.thread.affinity=[0-9,20-29],[10-19,30-39]</code></pre>
</div>
</div>
<div class="paragraph">
<p>See <a href="https://en.wikipedia.org/wiki/Non-uniform_memory_access" target="_blank" rel="noopener">here</a>
for information on NUMA nodes.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_running_on_ec2"><a class="anchor" href="#_running_on_ec2"></a>Running on EC2</h2>
<div class="sectionbody">
<div class="paragraph">
<p>For the best performance of your Hazelcast on AWS EC2:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Select the newest Linux AMIs.</p>
</li>
<li>
<p>Select the HVM based instances.</p>
</li>
<li>
<p>Select at least a system with 8 vCPUs, e.g., c4.2xlarge. For an overview of all types of
EC2 instances, please check <a href="https://www.ec2instances.info" target="_blank" rel="noopener">this web page</a>.</p>
</li>
<li>
<p>Consider setting a placement group.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_back_pressure"><a class="anchor" href="#_back_pressure"></a>Back Pressure</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Hazelcast uses operations to make remote calls. For example, a <code>map.get</code> is an operation and
a <code>map.put</code> is one operation for the primary
and one operation for each of the backups, i.e., <code>map.put</code> is executed for the primary and also for each backup.
In most cases, there is a natural balance between the number of threads performing operations
and the number of operations being executed. However, the following may pile up this balance and operations
and eventually lead to <code>OutofMemoryException</code> (<code>OOME</code>):</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Asynchronous calls: With async calls, the system may be flooded with the requests.</p>
</li>
<li>
<p>Asynchronous backups: The asynchronous backups may be piling up.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>To prevent the system from crashing, Hazelcast provides back pressure. Back pressure works by:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>limiting the number of concurrent operation invocations</p>
</li>
<li>
<p>and periodically making an async backup sync.</p>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="_member_side"><a class="anchor" href="#_member_side"></a>Member Side</h3>
<div class="paragraph">
<p>Back pressure is disabled by default and you can enable it using the following system property:</p>
</div>
<div class="paragraph">
<p><code>hazelcast.backpressure.enabled</code></p>
</div>
<div class="paragraph">
<p>To control the number of concurrent invocations, you can configure the number of invocations allowed per partition using the
following system property:</p>
</div>
<div class="paragraph">
<p><code>hazelcast.backpressure.max.concurrent.invocations.per.partition</code></p>
</div>
<div class="paragraph">
<p>The default value of this system property is 100. Using a default configuration a system is allowed to
have (271 + 1) * 100 = 27200 concurrent invocations (271 partitions + 1 for generic operations).</p>
</div>
<div class="paragraph">
<p>Back pressure is only applied to normal operations. System operations like heart beats and partition migration operations
are not influenced by back pressure. 27200 invocations might seem like a lot, but keep in mind that executing a task on <code>IExecutor</code>
or acquiring a lock also requires an operation.</p>
</div>
<div class="paragraph">
<p>If the maximum number of invocations has been reached, Hazelcast automatically applies an exponential backoff policy. This
gives the system some time to deal with the load.
Using the following system property, you can configure the maximum time to wait before a <code>HazelcastOverloadException</code> is thrown:</p>
</div>
<div class="paragraph">
<p><code>hazelcast.backpressure.backoff.timeout.millis</code></p>
</div>
<div class="paragraph">
<p>This system property&#8217;s default value is 60000 milliseconds.</p>
</div>
<div class="paragraph">
<p>The Health Monitor keeps an eye on the usage of the invocations.
If it sees a member has consumed 70% or more of the invocations, it starts to log health messages.</p>
</div>
<div class="paragraph">
<p>Apart from controlling the number of invocations, you also need to control the number of pending async backups.
This is done by periodically making these backups sync instead of async.
This forces all pending backups to get drained. For this, Hazelcast tracks the number of
asynchronous backups for each partition. At every <strong>Nth</strong> call, one synchronization is forced. This <strong>N</strong> is
controlled through the following property:</p>
</div>
<div class="paragraph">
<p><code>hazelcast.backpressure.syncwindow</code></p>
</div>
<div class="paragraph">
<p>This system property&#8217;s default value is 100. It means, out of 100 <strong>asynchronous</strong> backups,
Hazelcast makes 1 of them a <strong>synchronous</strong> one. A randomization is added,
so the sync window with default configuration is between 75 and 125
invocations.</p>
</div>
</div>
<div class="sect2">
<h3 id="_client_side"><a class="anchor" href="#_client_side"></a>Client Side</h3>
<div class="paragraph">
<p>To prevent the system on the client side from overloading, you can apply
a constraint on the number of concurrent invocations.
You can use the following system property on the client side for this purpose:</p>
</div>
<div class="paragraph">
<p><code>hazelcast.client.max.concurrent.invocations</code></p>
</div>
<div class="paragraph">
<p>This property defines the maximum allowed number of concurrent invocations.
When it is not explicitly set, it has the value <code>Integer.MAX_VALUE</code> by default, which means infinite.
When you set it and if the maximum number of concurrent invocations is exceeded this value,
Hazelcast throws <code>HazelcastOverloadException</code> when a new invocation comes in.</p>
</div>
<div class="paragraph">
<p>Please note that back off timeout and controlling the number of
pending async backups (sync window) is not supported on the client side.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
See the <a href="#system-properties">System Properties appendix</a> to learn how to configure the system properties.
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_threading_model"><a class="anchor" href="#_threading_model"></a>Threading Model</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Your application server has its own threads. Hazelcast does not use these; it manages its own threads.</p>
</div>
<div class="sect2">
<h3 id="_io_threading"><a class="anchor" href="#_io_threading"></a>I/O Threading</h3>
<div class="paragraph">
<p>Hazelcast uses a pool of threads for I/O. A single thread does not perform all the I/O.
Instead, multiple threads perform the I/O. On each cluster member, the I/O threading is split up in 3 types of I/O threads:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>I/O thread for the accept requests</p>
</li>
<li>
<p>I/O threads to read data from other members/clients</p>
</li>
<li>
<p>I/O threads to write data to other members/clients</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>You can configure the number of I/O threads using the <code>hazelcast.io.thread.count</code> system property.
Its default value is 3 per member. If 3 is used, in total there are 7 I/O threads:
1 accept I/O thread, 3 read I/O threads and 3 write I/O threads. Each I/O thread has
its own Selector instance and waits on the <code>Selector.select</code> if there is nothing to do.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
You can also specify counts for input and output threads separately.
There are <code>hazelcast.io.input.thread.count</code> and <code>hazelcast.io.output.thread.count</code> properties for this purpose.
See the <a href="#system-properties">System Properties appendix</a> for information on these properties and how to set them.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Hazelcast periodically scans utilization of each I/O thread and
can decide to migrate a connection to a new thread if
the existing thread is servicing a disproportionate number of I/O events.
You can customize the scanning interval by configuring the <code>hazelcast.io.balancer.interval.seconds</code> system property;
its default interval is 20 seconds. You can disable the balancing process by setting this property to a negative value.</p>
</div>
<div class="paragraph">
<p>In case of the read I/O thread, when sufficient bytes for a packet have been received, the <code>Packet</code> object is created. This <code>Packet</code> object is
then sent to the system where it is de-multiplexed. If the <code>Packet</code> header signals that it is an operation/response, the <code>Packet</code> is handed
over to the operation service (see the <a href="#operation-threading">Operation Threading section</a>). If the <code>Packet</code> is an event, it is handed
over to the event service (see the <a href="#event-threading">Event Threading section</a>).</p>
</div>
</div>
<div class="sect2">
<h3 id="_event_threading"><a class="anchor" href="#_event_threading"></a>Event Threading</h3>
<div class="paragraph">
<p>Hazelcast uses a shared event system to deal with components that rely on events, such as topic, collections, listeners and Near Cache.</p>
</div>
<div class="paragraph">
<p>Each cluster member has an array of event threads and each thread has its own work queue. When an event is produced,
either locally or remotely, an event thread is selected (depending on if there is a message ordering) and the event is placed
in the work queue for that event thread.</p>
</div>
<div class="paragraph">
<p>You can set the following properties
to alter the system&#8217;s behavior:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>hazelcast.event.thread.count</code>: Number of event-threads in this array. Its default value is 5.</p>
</li>
<li>
<p><code>hazelcast.event.queue.capacity</code>: Capacity of the work queue. Its default value is 1000000.</p>
</li>
<li>
<p><code>hazelcast.event.queue.timeout.millis</code>: Timeout for placing an item on the work queue in milliseconds. Its default value is 250 milliseconds.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>If you process a lot of events and have many cores, changing the value of <code>hazelcast.event.thread.count</code> property to
a higher value is a good practice. This way, more events can be processed in parallel.</p>
</div>
<div class="paragraph">
<p>Multiple components share the same event queues. If there are 2 topics, say A and B, for certain messages
they may share the same queue(s) and hence the same event thread. If there are a lot of pending messages produced by A, then B needs to wait.
Also, when processing a message from A takes a lot of time and the event thread is used for that, B suffers from this.
That is why it is better to offload processing to a dedicated thread (pool) so that systems are better isolated.</p>
</div>
<div class="paragraph">
<p>If the events are produced at a higher rate than they are consumed, the queue grows in size. To prevent overloading the system
and running into an <code>OutOfMemoryException</code>, the queue is given a capacity of 1 million items. When the maximum capacity is reached, the items are
dropped. This means that the event system is a 'best effort' system. There is no guarantee that you are going to get an
event. Topic A might have a lot of pending messages and therefore B cannot receive messages because the queue
has no capacity and messages for B are dropped.</p>
</div>
</div>
<div class="sect2">
<h3 id="_iexecutor_threading"><a class="anchor" href="#_iexecutor_threading"></a>IExecutor Threading</h3>
<div class="paragraph">
<p>Executor threading is straight forward. When a task is received to be executed on Executor E, then E will have its
own <code>ThreadPoolExecutor</code> instance and the work is placed in the work queue of this executor.
Thus, Executors are fully isolated, but still share the same underlying hardware - most importantly the CPUs.</p>
</div>
<div class="paragraph">
<p>You can configure the IExecutor using the <code>ExecutorConfig</code> (programmatic configuration) or
using <code>&lt;executor&gt;</code> (declarative configuration). See also the <a href="#configuring-executor-service">Configuring Executor Service section</a>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_operation_threading"><a class="anchor" href="#_operation_threading"></a>Operation Threading</h3>
<div class="paragraph">
<p>The following are the operation types:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>operations that are aware of a certain partition, e.g., <code>IMap.get(key)</code></p>
</li>
<li>
<p>operations that are not partition aware, e.g., <code>IExecutorService.executeOnMember(command, member)</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Each of these operation types has a different threading model explained in the following sections.</p>
</div>
<div class="sect3">
<h4 id="_partition_aware_operations"><a class="anchor" href="#_partition_aware_operations"></a>Partition-aware Operations</h4>
<div class="paragraph">
<p>To execute partition-aware operations, an array of operation threads is created.
The default value of this array&#8217;s size is the number of cores and it has a minimum value of 2.
This value can be changed using the <code>hazelcast.operation.thread.count</code> property.</p>
</div>
<div class="paragraph">
<p>Each operation thread has its own work queue and it consumes messages from this work queue. If a partition-aware
operation needs to be scheduled, the right thread is found using the formula below.</p>
</div>
<div class="paragraph">
<p><code>threadIndex = partitionId % partition thread-count</code></p>
</div>
<div class="paragraph">
<p>After the <code>threadIndex</code> is determined, the operation is put in the work queue of that operation thread. This means the followings:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A single operation thread executes operations for multiple partitions;
if there are 271 partitions and 10 partition threads, then roughly every operation thread executes operations for 27 partitions.</p>
</li>
<li>
<p>Each partition belongs to only 1 operation thread.
All operations for a partition are always handled by exactly the same operation thread.</p>
</li>
<li>
<p>Concurrency control is not needed to deal with partition-aware operations because
once a partition-aware operation is put in the work queue of a partition-aware operation thread, only 1 thread is able to touch that partition.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Because of this threading strategy, there are two forms of false sharing you need to be aware of:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>False sharing of the partition - two completely independent data structures share the same partition.
For example, if there is a map <code>employees</code> and a map <code>orders</code>,
the method <code>employees.get("peter")</code> running on partition 25 may be blocked by
the method <code>orders.get(1234)</code> also running on partition 25.
If independent data structures share the same partition, a slow operation on one data structure can slow down the other data structures.</p>
</li>
<li>
<p>False sharing of the partition-aware operation thread - each operation thread is responsible for executing
operations on a number of partitions. For example, <strong>thread 1</strong> could be responsible for partitions 0, 10, 20, etc. and <strong>thread-2</strong> could be responsible for partitions
1, 11, 21, etc. If an operation for partition 1 takes a lot of time, it blocks the execution of an operation for partition
11 because both of them are mapped to the same operation thread.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>You need to be careful with long running operations because you could starve operations of a thread.
As a general rule, the partition thread should be released as soon as possible because operations are not designed
as long running operations. That is why, for example, it is very dangerous to execute a long running operation
using <code>AtomicReference.alter()</code> or an <code>IMap.executeOnKey()</code>, because these operations block other operations to be executed.</p>
</div>
<div class="paragraph">
<p>Currently, there is no support for work stealing. Different partitions that map to the same thread may need to wait
till one of the partitions is finished, even though there are other free partition-aware operation threads available.</p>
</div>
<div class="paragraph">
<p><strong>Example:</strong></p>
</div>
<div class="paragraph">
<p>Take a cluster with three members. Two members have 90 primary partitions and one member has 91 primary partitions. Let&#8217;s
say you have one CPU and four cores per CPU. By default, four operation threads will be allocated to serve 90 or 91 partitions.</p>
</div>
</div>
<div class="sect3">
<h4 id="_non_partition_aware_operations"><a class="anchor" href="#_non_partition_aware_operations"></a>Non-Partition-aware Operations</h4>
<div class="paragraph">
<p>To execute operations that are not partition-aware, e.g., <code>IExecutorService.executeOnMember(command, member)</code>, generic operation
threads are used. When the Hazelcast instance is started, an array of operation threads is created. The size of this array
has a default value of the number of cores divided by two with a minimum value of 2. It can be changed using the
<code>hazelcast.operation.generic.thread.count</code> property.</p>
</div>
<div class="paragraph">
<p>A non-partition-aware operation thread does not execute an operation for a specific partition. Only partition-aware
  operation threads execute partition-aware operations.</p>
</div>
<div class="paragraph">
<p>Unlike the partition-aware operation threads, all the generic operation threads share the same work queue: <code>genericWorkQueue</code>.</p>
</div>
<div class="paragraph">
<p>If a non-partition-aware operation needs to be executed, it is placed in that work queue and any generic operation
thread can execute it. The big advantage is that you automatically have work balancing since any generic operation
thread is allowed to pick up work from this queue.</p>
</div>
<div class="paragraph">
<p>The disadvantage is that this shared queue can be a point of contention. You may not see this contention in
production since performance is dominated by I/O and the system does not run many non-partition-aware operations.</p>
</div>
</div>
<div class="sect3">
<h4 id="_priority_operations"><a class="anchor" href="#_priority_operations"></a>Priority Operations</h4>
<div class="paragraph">
<p>In some cases, the system needs to run operations with a higher priority, e.g., an important system operation.
To support priority operations, Hazelcast has the following features:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>For partition-aware operations: Each partition thread has its own work queue and it also has a priority
work queue. The partition thread always checks the priority queue before it processes work from its normal work queue.</p>
</li>
<li>
<p>For non-partition-aware operations: Next to the <code>genericWorkQueue</code>, there is also a <code>genericPriorityWorkQueue</code>. When a priority operation
needs to be run, it is put in the <code>genericPriorityWorkQueue</code>. Like the partition-aware operation threads, a generic
operation thread first checks the <code>genericPriorityWorkQueue</code> for work.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Since a worker thread blocks on the normal work queue (either partition specific or generic), a priority operation
may not be picked up because it is not put in the queue where it is blocking. Hazelcast always sends a 'kick the worker' operation that
only triggers the worker to wake up and check the priority queue.</p>
</div>
</div>
<div class="sect3">
<h4 id="_operation_response_and_invocation_future"><a class="anchor" href="#_operation_response_and_invocation_future"></a>Operation-response and Invocation-future</h4>
<div class="paragraph">
<p>When an Operation is invoked, a <code>Future</code> is returned. See the example code below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">GetOperation operation = new GetOperation( mapName, key );
Future future = operationService.invoke( operation );
future.get();</code></pre>
</div>
</div>
<div class="paragraph">
<p>The calling side blocks for a reply. In this case, <code>GetOperation</code> is set in the work queue for the partition of <code>key</code>, where
it eventually is executed. Upon execution, a response is returned and placed on the <code>genericWorkQueue</code> where it is executed by a
"generic operation thread". This thread signals the <code>future</code> and notifies the blocked thread that a response is available.
Hazelcast has a plan of exposing this <code>future</code> to the outside world, and we will provide the ability to register a completion listener so you can perform asynchronous calls.</p>
</div>
</div>
<div class="sect3">
<h4 id="_local_calls"><a class="anchor" href="#_local_calls"></a>Local Calls</h4>
<div class="paragraph">
<p>When a local partition-aware call is done, an operation is made and handed over to the work queue of the correct partition operation thread,
and a <code>future</code> is returned. When the calling thread calls <code>get</code> on that <code>future</code>, it acquires a lock and waits for the result
to become available. When a response is calculated, the <code>future</code> is looked up and the waiting thread is notified.</p>
</div>
<div class="paragraph">
<p>In the future, this will be optimized to reduce the amount of expensive systems calls, such as <code>lock.acquire()</code>/<code>notify()</code> and the expensive
interaction with the operation-queue. Probably, we will add support for a caller-runs mode, so that an operation is directly run on
the calling thread.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_slowoperationdetector"><a class="anchor" href="#_slowoperationdetector"></a>SlowOperationDetector</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The <code>SlowOperationDetector</code> monitors the operation threads and collects information about all slow operations.
An <code>Operation</code> is a task executed by a generic or partition thread (see <a href="#operation-threading">Operation Threading</a>).
An operation is considered as slow when it takes more computation time than the configured threshold.</p>
</div>
<div class="paragraph">
<p>The <code>SlowOperationDetector</code> stores the fully qualified classname of the operation and its stacktrace as well as
operation details, start time and duration of each slow invocation. All collected data is available in
the <a href="https://docs.hazelcast.org/docs/management-center/latest/manual/html/index.html#monitoring-members" target="_blank" rel="noopener">Management Center</a>.</p>
</div>
<div class="paragraph">
<p>The <code>SlowOperationDetector</code> is configured via the following system properties.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>hazelcast.slow.operation.detector.enabled</code></p>
</li>
<li>
<p><code>hazelcast.slow.operation.detector.log.purge.interval.seconds</code></p>
</li>
<li>
<p><code>hazelcast.slow.operation.detector.log.retention.seconds</code></p>
</li>
<li>
<p><code>hazelcast.slow.operation.detector.stacktrace.logging.enabled</code></p>
</li>
<li>
<p><code>hazelcast.slow.operation.detector.threshold.millis</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>See the <a href="#system-properties">System Properties appendix</a> for explanations of these properties.</p>
</div>
<div class="sect2">
<h3 id="_logging_of_slow_operations"><a class="anchor" href="#_logging_of_slow_operations"></a>Logging of Slow Operations</h3>
<div class="paragraph">
<p>The detected slow operations are logged as warnings in the Hazelcast log files:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>WARN 2015-05-07 11:05:30,890 SlowOperationDetector: [127.0.0.1]:5701
  Slow operation detected: com.hazelcast.map.impl.operation.PutOperation
  Hint: You can enable the logging of stacktraces with the following config
  property: hazelcast.slow.operation.detector.stacktrace.logging.enabled
WARN 2015-05-07 11:05:30,891 SlowOperationDetector: [127.0.0.1]:5701
  Slow operation detected: com.hazelcast.map.impl.operation.PutOperation
  (2 invocations)
WARN 2015-05-07 11:05:30,892 SlowOperationDetector: [127.0.0.1]:5701
  Slow operation detected: com.hazelcast.map.impl.operation.PutOperation
  (3 invocations)</code></pre>
</div>
</div>
<div class="paragraph">
<p>Stacktraces are always reported to the Management Center, but by default they are not printed to keep the log size small.
If logging of stacktraces is enabled, the full stacktrace is printed every 100 invocations.
All other invocations print a shortened version.</p>
</div>
</div>
<div class="sect2">
<h3 id="_purging_of_slow_operation_logs"><a class="anchor" href="#_purging_of_slow_operation_logs"></a>Purging of Slow Operation Logs</h3>
<div class="paragraph">
<p>Since a Hazelcast cluster can run for a very long time, Hazelcast purges the slow operation logs periodically to prevent an OOME.
You can configure the purge interval and the retention time for each invocation.</p>
</div>
<div class="paragraph">
<p>The purging removes each invocation whose retention time is exceeded.
When all invocations are purged from a slow operation log, the log is deleted.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_near_cache"><a class="anchor" href="#_near_cache"></a>Near Cache</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Map or Cache entries in Hazelcast are partitioned across the cluster members.
Hazelcast clients do not have local data at all. Suppose you read the key <code>k</code> a number of times from
a Hazelcast client or <code>k</code> is owned by another member in your cluster.
Then each <code>map.get(k)</code> or <code>cache.get(k)</code> will be a remote operation, which creates a lot of network trips.
If you have a data structure that is mostly read, then you should consider creating a local Near Cache,
so that reads are sped up and less network traffic is created.</p>
</div>
<div class="paragraph">
<p>These benefits do not come for free. See the following trade-offs:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Members with a Near Cache has to hold the extra cached data, which increases memory consumption.</p>
</li>
<li>
<p>If invalidation is enabled and entries are updated frequently, then invalidations will be costly.</p>
</li>
<li>
<p>Near Cache breaks the strong consistency guarantees; you might be reading stale data.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Near Cache is highly recommended for data structures that are mostly read.</p>
</div>
<div class="paragraph">
<p>In a client/server system you must enable the Near Cache separately on the client, without the need
to configure it on the server. Please note that Near Cache configuration is specific to the server or client itself:
a data structure on a server may not have Near Cache configured while the same data structure on a client may have Near Cache configured.
They also can have different Near Cache configurations.</p>
</div>
<div class="paragraph">
<p>If you are using Near Cache, you should take into account that
your hits to the keys in the Near Cache are not reflected as hits to the original keys on the primary members.
This has for example an impact on IMap&#8217;s maximum idle seconds or time-to-live seconds expiration.
Therefore, even though there is a hit on a key in Near Cache, your original key on the primary member may expire.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Near Cache works only when you access data via <code>map.get(k)</code> or <code>cache.get(k)</code> methods.
Data returned using a predicate is not stored in the Near Cache.
</td>
</tr>
</table>
</div>
<div class="sect2">
<h3 id="_hazelcast_data_structures_with_near_cache_support"><a class="anchor" href="#_hazelcast_data_structures_with_near_cache_support"></a>Hazelcast Data Structures with Near Cache Support</h3>
<div class="paragraph">
<p>The following matrix shows the Hazelcast data structures with Near Cache support.
Please have a look at the next section for a detailed explanation of <code>cache-local-entries</code>, <code>local-update-policy</code>, <code>preloader</code> and <code>serialize-keys</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Data structure</th>
<th class="tableblock halign-left valign-top">Near Cache Support</th>
<th class="tableblock halign-left valign-top"><code>cache-local-entries</code></th>
<th class="tableblock halign-left valign-top"><code>local-update-policy</code></th>
<th class="tableblock halign-left valign-top"><code>preloader</code></th>
<th class="tableblock halign-left valign-top"><code>serialize-keys</code></th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">IMap member</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yes</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">IMap client</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yes</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">JCache member</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">JCache client</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yes</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ReplicatedMap member</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ReplicatedMap client</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TransactionalMap member</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">limited</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TransactionalMap client</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">no</p></td>
</tr>
</tbody>
</table>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Even though lite members do not store any data for Hazelcast data structures,
you can enable Near Cache on lite members for faster reads.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_configuring_near_cache"><a class="anchor" href="#_configuring_near_cache"></a>Configuring Near Cache</h3>
<div class="paragraph">
<p>The following shows the configuration for the Hazelcast Near Cache.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Please keep in mind that, if you want to use near cache on a Hazelcast member,
configure it on the member; if you want to use it on a Hazelcast client, configure it on the client.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><strong>Declarative Configuration:</strong></p>
</div>
<div class="listingblock primary">
<div class="title">XML</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">&lt;hazelcast&gt;
    ...
    &lt;near-cache name="myDataStructure"&gt;
        &lt;in-memory-format&gt;BINARY&lt;/in-memory-format&gt;
        &lt;invalidate-on-change&gt;true&lt;/invalidate-on-change&gt;
        &lt;time-to-live-seconds&gt;0&lt;/time-to-live-seconds&gt;
        &lt;max-idle-seconds&gt;60&lt;/max-idle-seconds&gt;
        &lt;eviction eviction-policy="LFU"
            max-size-policy= "ENTRY_COUNT"
            size="1000"/&gt;
        &lt;cache-local-entries&gt;false&lt;/cache-local-entries&gt;
        &lt;local-update-policy&gt;INVALIDATE&lt;/local-update-policy&gt;
        &lt;preloader enabled="true"
             directory="nearcache-example"
             store-initial-delay-seconds="0"
             store-interval-seconds="0"/&gt;
    &lt;/near-cache&gt;
    ...
&lt;/hazelcast&gt;</code></pre>
</div>
</div>
<div class="listingblock secondary">
<div class="title">YAML</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yml hljs" data-lang="yml">hazelcast:
    near-cache:
      myDataStructure:
        in-memory-format: BINARY
        invalidate-on-change: true
        time-to-live-seconds: 0
        max-idle-seconds: 60
        eviction:
          size: 1000
          max-size-policy: ENTRY_COUNT
          eviction-policy: LFU
        cache-local-entries: false
        local-update-policy: INVALIDATE
        preloader:
          enabled: true
          directory: nearcache-example
          store-initial-delay-seconds: 0
          store-interval-seconds: 0</code></pre>
</div>
</div>
<div class="paragraph">
<p>The element <code>&lt;near-cache&gt;</code> has an optional attribute <code>name</code> whose default value is <code>default</code>.</p>
</div>
<div class="paragraph">
<p><strong>Programmatic Configuration:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">        EvictionConfig evictionConfig = new EvictionConfig()
                .setMaxSizePolicy(MaxSizePolicy.ENTRY_COUNT)
                .setEvictionPolicy(EvictionPolicy.LRU)
                .setSize( 1 );

        NearCachePreloaderConfig preloaderConfig = new NearCachePreloaderConfig()
                .setEnabled(true)
                .setDirectory("nearcache-example")
                .setStoreInitialDelaySeconds( 1 )
                .setStoreIntervalSeconds( 2 );

        NearCacheConfig nearCacheConfig = new NearCacheConfig()
                .setName("myDataStructure")
                .setInMemoryFormat(InMemoryFormat.BINARY)
                .setSerializeKeys(true)
                .setInvalidateOnChange(false)
                .setTimeToLiveSeconds( 1 )
                .setMaxIdleSeconds( 5 )
                .setEvictionConfig(evictionConfig)
                .setCacheLocalEntries(true)
                .setLocalUpdatePolicy(NearCacheConfig.LocalUpdatePolicy.CACHE_ON_UPDATE)
                .setPreloaderConfig(preloaderConfig);</code></pre>
</div>
</div>
<div class="paragraph">
<p>The class <a href="https://docs.hazelcast.org/docs/4.1/javadoc/com/hazelcast/config/NearCacheConfig.html" target="_blank" rel="noopener">NearCacheConfig</a>
is used for all supported Hazelcast data structures on members and clients.</p>
</div>
<div class="paragraph">
<p>The following are the descriptions of all configuration elements and attributes:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>in-memory-format</code>: Specifies in which format data is stored in your Near Cache.
Note that a map&#8217;s in-memory format can be different from that of its Near Cache. Available values are as follows:</p>
<div class="ulist">
<ul>
<li>
<p><code>BINARY</code>: Data is stored in serialized binary format (default value).</p>
</li>
<li>
<p><code>OBJECT</code>: Data is stored in deserialized form.</p>
</li>
<li>
<p><code>NATIVE</code>: Data is stored in the Near Cache that uses Hazelcast&#8217;s High-Density Memory Store feature.
This option is available only in Hazelcast IMDG Enterprise HD. Note that a map and
its Near Cache can independently use High-Density Memory Store.
For example, while your map does not use High-Density Memory Store, its Near Cache can use it.</p>
</li>
</ul>
</div>
</li>
<li>
<p><code>invalidate-on-change</code>: Specifies whether the cached entries are evicted when the entries are updated or removed.
Its default value is true.</p>
</li>
<li>
<p><code>time-to-live-seconds</code>: Maximum number of seconds for each entry to stay in the Near Cache.
Entries that are older than this period are automatically evicted from the Near Cache.
Regardless of the eviction policy used, <code>time-to-live-seconds</code> still applies.
Any integer between 0 and <code>Integer.MAX_VALUE</code>. 0 means infinite. Its default value is 0.</p>
</li>
<li>
<p><code>max-idle-seconds</code>: Maximum number of seconds each entry can stay in the Near Cache as untouched (not read).
Entries that are not read more than this period are removed from the Near Cache.
Any integer between 0 and <code>Integer.MAX_VALUE</code>. 0 means <code>Integer.MAX_VALUE</code>. Its default value is 0.</p>
</li>
<li>
<p><code>eviction</code>: Specifies the eviction behavior when you use High-Density Memory Store for your Near Cache.
It has the following attributes:</p>
<div class="ulist">
<ul>
<li>
<p><code>eviction-policy</code>: Eviction policy configuration. Available values are as follows:</p>
<div class="ulist">
<ul>
<li>
<p><code>LRU</code>: Least Recently Used (default value).</p>
</li>
<li>
<p><code>LFU</code>: Least Frequently Used.</p>
</li>
<li>
<p><code>NONE</code>: No items are evicted and the property <code>max-size</code> is ignored.
You still can combine it with <code>time-to-live-seconds</code> and <code>max-idle-seconds</code> to evict items from the Near Cache.</p>
</li>
<li>
<p><code>RANDOM</code>: A random item is evicted.</p>
</li>
</ul>
</div>
</li>
<li>
<p><code>max-size-policy</code>: Maximum size policy for eviction of the Near Cache. Available values are as follows:</p>
<div class="ulist">
<ul>
<li>
<p><code>ENTRY_COUNT</code>: Maximum size based on the entry count in the Near Cache (default value).</p>
</li>
<li>
<p><code>USED_NATIVE_MEMORY_SIZE</code>: Maximum used native memory size of the specified Near Cache in MB to trigger the eviction.
If the used native memory size exceeds this threshold, the eviction is triggered.
Available only for <code>NATIVE</code> in-memory format. This is supported only by Hazelcast IMDG Enterprise.</p>
</li>
<li>
<p><code>USED_NATIVE_MEMORY_PERCENTAGE</code>: Maximum used native memory percentage of the specified Near Cache to trigger the eviction.
If the native memory usage percentage (relative to maximum native memory size) exceeds this threshold, the eviction is triggered.
Available only for <code>NATIVE</code> in-memory format. This is supported only by Hazelcast IMDG Enterprise.</p>
</li>
<li>
<p><code>FREE_NATIVE_MEMORY_SIZE</code>: Minimum free native memory size of the specified Near Cache in MB to trigger the eviction.
If free native memory size goes below this threshold, eviction is triggered. Available only for <code>NATIVE</code> in-memory format.
This is supported only by Hazelcast IMDG Enterprise.</p>
</li>
<li>
<p><code>FREE_NATIVE_MEMORY_PERCENTAGE</code>: Minimum free native memory percentage of the specified Near Cache to trigger eviction.
If free native memory percentage (relative to maximum native memory size) goes below this threshold, eviction is triggered.
Available only for <code>NATIVE</code> in-memory format. This is supported only by Hazelcast IMDG Enterprise.</p>
</li>
</ul>
</div>
</li>
<li>
<p><code>size</code>: Maximum size of the Near Cache used for <code>max-size-policy</code>. When this is reached the Near Cache is evicted based on
the policy defined. Any integer between <code>1</code> and <code>Integer.MAX_VALUE</code>. This value has different defaults, depending on the data structure.</p>
<div class="ulist">
<ul>
<li>
<p><code>IMap</code>: Its default value is <code>Integer.MAX_VALUE</code> for on-heap maps and <code>10000</code> for the <code>NATIVE</code> in-memory format.</p>
</li>
<li>
<p><code>JCache</code>: Its default value is <code>10000</code>.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
<li>
<p><code>cache-local-entries</code>: Specifies whether the local entries are cached. It can be useful when in-memory format for
Near Cache is different from that of the map. By default, it is disabled.
Is just available on Hazelcast members, not on Hazelcast clients (which have no local entries).</p>
</li>
<li>
<p><code>local-update-policy</code>: Specifies the update policy of the local Near Cache.
It is available on JCache clients. Available values are as follows:</p>
<div class="ulist">
<ul>
<li>
<p><code>INVALIDATE</code>: Removes the Near Cache entry on mutation. After the mutative call to the member completes but before the operation returns to the caller,
the Near Cache entry is removed. Until the mutative operation completes, the readers still continue to read the old value.
But as soon as the update completes the Near Cache entry is removed.
Any threads reading the key after this point will have a Near Cache miss and call through to the member, obtaining the new entry.
This setting provides read-your-writes consistency. This is the default setting.</p>
</li>
<li>
<p><code>CACHE_ON_UPDATE</code>: Updates the Near Cache entry on mutation. After the mutative call to the member completes but before the put returns to the caller,
the Near Cache entry is updated.
So a remove will remove it and one of the put methods will update it to the new value.
Until the update/remove operation completes, the entry&#8217;s old value can still be read from the Near Cache.
But before the call completes the Near Cache entry is updated. Any threads reading the key after this point read the new entry.
If the mutative operation was a remove, the key will no longer exist in the cache, both the Near Cache and the original copy in the member.
The member initiates an invalidate event to any other Near Caches, however the caller Near Cache is
not invalidated as it already has the new value. This setting also provides read-your-writes consistency.</p>
</li>
</ul>
</div>
</li>
<li>
<p><code>preloader</code>: Specifies if the Near Cache should store and pre-load its keys for a faster re-population after
a Hazelcast client restart. Is just available on IMap and JCache clients. It has the following attributes:</p>
<div class="ulist">
<ul>
<li>
<p><code>enabled</code>: Specifies whether the preloader for this Near Cache is enabled or not, <code>true</code> or <code>false</code>.</p>
</li>
<li>
<p><code>directory</code>: Specifies the parent directory for the preloader of this Near Cache. The filenames for
the preloader storage are generated from the Near Cache name. You can additionally specify the parent directory
to have multiple clients on the same machine with the same Near Cache names.</p>
</li>
<li>
<p><code>store-initial-delay-seconds</code>: Specifies the delay in seconds until the keys of this Near Cache
are stored for the first time. Its default value is <code>600</code> seconds.</p>
</li>
<li>
<p><code>store-interval-seconds</code>: Specifies the interval in seconds in which the keys of this Near Cache are stored.
Its default value is <code>600</code> seconds.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_near_cache_configuration_examples"><a class="anchor" href="#_near_cache_configuration_examples"></a>Near Cache Configuration Examples</h3>
<div class="paragraph">
<p>This section shows some configuration examples for different Hazelcast data structures.</p>
</div>
<div class="sect3">
<h4 id="_near_cache_example_for_imap"><a class="anchor" href="#_near_cache_example_for_imap"></a>Near Cache Example for IMap</h4>
<div class="paragraph">
<p>The following are configuration examples for IMap Near Caches for Hazelcast members and clients.</p>
</div>
<div class="listingblock primary">
<div class="title">XML</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">&lt;hazelcast&gt;
    ...
    &lt;map name="mostlyReadMap"&gt;
        &lt;in-memory-format&gt;BINARY&lt;/in-memory-format&gt;
        &lt;near-cache&gt;
            &lt;in-memory-format&gt;OBJECT&lt;/in-memory-format&gt;
            &lt;invalidate-on-change&gt;false&lt;/invalidate-on-change&gt;
            &lt;time-to-live-seconds&gt;600&lt;/time-to-live-seconds&gt;
            &lt;eviction eviction-policy="NONE" max-size-policy="ENTRY_COUNT" size="5000"/&gt;
            &lt;cache-local-entries&gt;true&lt;/cache-local-entries&gt;
        &lt;/near-cache&gt;
    &lt;/map&gt;
    ...
&lt;/hazelcast&gt;</code></pre>
</div>
</div>
<div class="listingblock secondary">
<div class="title">YAML</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yml hljs" data-lang="yml">hazelcast:
  map:
    mostlyReadMap:
      in-memory-format: BINARY
      near-cache:
        in-memory-format: OBJECT
        invalidate-on-change: false
        time-to-live-seconds: 600
        eviction:
          eviction-policy: NONE
          max-size-policy: ENTRY_COUNT
          size: 5000
          cache-local-entries: true</code></pre>
</div>
</div>
<div class="listingblock secondary">
<div class="title">JAVA</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">EvictionConfig evictionConfig = new EvictionConfig()
  .setEvictionPolicy(EvictionPolicy.NONE)
  .setMaximumSizePolicy(MaxSizePolicy.ENTRY_COUNT)
  .setSize(5000);

NearCacheConfig nearCacheConfig = new NearCacheConfig()
  .setInMemoryFormat(InMemoryFormat.OBJECT)
  .setInvalidateOnChange(false)
  .setTimeToLiveSeconds(600)
  .setEvictionConfig(evictionConfig);

Config config = new Config();
config.getMapConfig("mostlyReadMap")
  .setInMemoryFormat(InMemoryFormat.BINARY)
  .setNearCacheConfig(nearCacheConfig);</code></pre>
</div>
</div>
<div class="paragraph">
<p>The Near Cache configuration for maps on members is a child of the map configuration,
so you do not have to define the map name in the Near Cache configuration.</p>
</div>
<div class="listingblock primary">
<div class="title">XML</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">&lt;hazelcast-client&gt;
    ...
    &lt;near-cache name="mostlyReadMap"&gt;
        &lt;in-memory-format&gt;OBJECT&lt;/in-memory-format&gt;
        &lt;invalidate-on-change&gt;true&lt;/invalidate-on-change&gt;
        &lt;eviction eviction-policy="LRU" max-size-policy="ENTRY_COUNT" size="50000"/&gt;
    &lt;/near-cache&gt;
    ...
&lt;/hazelcast-client&gt;</code></pre>
</div>
</div>
<div class="listingblock secondary">
<div class="title">YAML</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yml hljs" data-lang="yml">hazelcast-client:
  near-cache:
    mostlyReadMap:
      in-memory-format: OBJECT
      invalidate-on-change: true
      eviction:
        eviction-policy: LRU
        max-size-policy: ENTRY_COUNT
        size: 50000</code></pre>
</div>
</div>
<div class="listingblock secondary">
<div class="title">JAVA</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">EvictionConfig evictionConfig = new EvictionConfig()
  .setEvictionPolicy(EvictionPolicy.LRU)
  .setMaximumSizePolicy(MaxSizePolicy.ENTRY_COUNT)
  .setSize(50000);

NearCacheConfig nearCacheConfig = new NearCacheConfig()
  .setName("mostlyReadMap")
  .setInMemoryFormat(InMemoryFormat.OBJECT)
  .setInvalidateOnChange(true)
  .setEvictionConfig(evictionConfig);

ClientConfig clientConfig = new ClientConfig()
  .addNearCacheConfig(nearCacheConfig);</code></pre>
</div>
</div>
<div class="paragraph">
<p>The Near Cache on the client side must have the same name as the data structure on the member for which
this Near Cache is being created. You can use wildcards, so in this example <code>mostlyRead*</code> would also match the map <code>mostlyReadMap</code>.</p>
</div>
<div class="paragraph">
<p>A Near Cache can have its own <code>in-memory-format</code> which is independent of the <code>in-memory-format</code> of the data structure.</p>
</div>
</div>
<div class="sect3">
<h4 id="_near_cache_example_for_jcache_clients"><a class="anchor" href="#_near_cache_example_for_jcache_clients"></a>Near Cache Example for JCache Clients</h4>
<div class="paragraph">
<p>The following is a configuration example for a JCache Near Cache for a Hazelcast client.</p>
</div>
<div class="listingblock primary">
<div class="title">XML</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">&lt;hazelcast-client&gt;
    ...
    &lt;near-cache name="mostlyReadCache"&gt;
        &lt;in-memory-format&gt;OBJECT&lt;/in-memory-format&gt;
        &lt;invalidate-on-change&gt;true&lt;/invalidate-on-change&gt;
        &lt;eviction eviction-policy="LRU" max-size-policy="ENTRY_COUNT" size="30000"/&gt;
        &lt;local-update-policy&gt;CACHE_ON_UPDATE&lt;/local-update-policy&gt;
    &lt;/near-cache&gt;
    ...
&lt;/hazelcast-client&gt;</code></pre>
</div>
</div>
<div class="listingblock secondary">
<div class="title">YAML</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yml hljs" data-lang="yml">hazelcast-client:
  near-cache:
    mostlyReadCache:
      in-memory-format: OBJECT
      invalidate-on-change: true
      eviction:
        eviction-policy: LRU
        max-size-policy: ENTRY_COUNT
        size: 30000
      local-update-policy: CACHE_ON_UPDATE</code></pre>
</div>
</div>
<div class="listingblock secondary">
<div class="title">JAVA</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">EvictionConfig evictionConfig = new EvictionConfig()
  .setEvictionPolicy(EvictionPolicy.LRU)
  .setMaximumSizePolicy(MaxSizePolicy.ENTRY_COUNT)
  .setSize(30000);

NearCacheConfig nearCacheConfig = new NearCacheConfig()
  .setName("mostlyReadCache")
  .setInMemoryFormat(InMemoryFormat.OBJECT)
  .setInvalidateOnChange(true)
  .setEvictionConfig(evictionConfig)
  .setLocalUpdatePolicy(LocalUpdatePolicy.CACHE_ON_UPDATE);

ClientConfig clientConfig = new ClientConfig()
  .addNearCacheConfig(nearCacheConfig);</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_example_for_near_cache_with_high_density_memory_store"><a class="anchor" href="#_example_for_near_cache_with_high_density_memory_store"></a>Example for Near Cache with High-Density Memory Store</h4>
<div class="paragraph">
<p><strong class="navy">Hazelcast IMDG Enterprise HD Feature</strong></p>
</div>
<div class="paragraph">
<p>The following is a configuration example for an IMap High-Density Near Cache for a Hazelcast member.</p>
</div>
<div class="listingblock primary">
<div class="title">XML</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">&lt;hazelcast&gt;
    ...
    &lt;map name="mostlyReadMapWithHighDensityNearCache"&gt;
        &lt;in-memory-format&gt;OBJECT&lt;/in-memory-format&gt;
        &lt;near-cache&gt;
            &lt;in-memory-format&gt;NATIVE&lt;/in-memory-format&gt;
            &lt;eviction eviction-policy="LFU" max-size-policy="USED_NATIVE_MEMORY_PERCENTAGE" size="90"/&gt;
        &lt;/near-cache&gt;
    &lt;/map&gt;
    ...
&lt;/hazelcast&gt;</code></pre>
</div>
</div>
<div class="listingblock secondary">
<div class="title">YAML</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yml hljs" data-lang="yml">hazelcast:
  map:
    mostlyReadMapWithHighDensityNearCache
      in-memory-format: OBJECT
      near-cache:
        in-memory-format: NATIVE
        eviction:
          eviction-policy: LFU
          max-size-policy: USED_NATIVE_MEMORY_PERCENTAGE
          size: 90</code></pre>
</div>
</div>
<div class="listingblock secondary">
<div class="title">JAVA</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">EvictionConfig evictionConfig = new EvictionConfig()
  .setEvictionPolicy(EvictionPolicy.LFU)
  .setMaximumSizePolicy(MaxSizePolicy.USED_NATIVE_MEMORY_PERCENTAGE)
  .setSize(90);

NearCacheConfig nearCacheConfig = new NearCacheConfig()
  .setInMemoryFormat(InMemoryFormat.NATIVE)
  .setEvictionConfig(evictionConfig);

Config config = new Config();
config.getMapConfig("mostlyReadMapWithHighDensityNearCache")
  .setInMemoryFormat(InMemoryFormat.OBJECT)
  .setNearCacheConfig(nearCacheConfig);</code></pre>
</div>
</div>
<div class="paragraph">
<p>Keep in mind that you should have already enabled the High-Density Memory Store usage for your cluster.
See the <a href="#configuring-high-density-memory-store">Configuring High-Density Memory Store section</a>.</p>
</div>
<div class="paragraph">
<p>Note that a map and its Near Cache can independently use High-Density Memory Store.
For example, if your map does not use High-Density Memory Store, its Near Cache can still use it.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_near_cache_eviction"><a class="anchor" href="#_near_cache_eviction"></a>Near Cache Eviction</h3>
<div class="paragraph">
<p>In the scope of Near Cache, eviction means evicting (clearing) the entries selected according to
the given <code>eviction-policy</code> when the specified <code>max-size-policy</code> has been reached.</p>
</div>
<div class="paragraph">
<p>The <code>max-size-policy</code> defines the state when the Near Cache is full and determines whether
the eviction should be triggered. The <code>size</code> is either interpreted as entry count, memory size or percentage, depending on the chosen policy.</p>
</div>
<div class="paragraph">
<p>Once the eviction is triggered the configured <code>eviction-policy</code> determines which, if any, entries must be evicted.</p>
</div>
<div class="paragraph">
<p>Note that the policies mentioned are configured under the <code>near-cache</code> configuration block, as seen in the above
<a href="#near-cache-configuration-examples">configuration examples</a>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_near_cache_expiration"><a class="anchor" href="#_near_cache_expiration"></a>Near Cache Expiration</h3>
<div class="paragraph">
<p>Expiration means the eviction of expired records. A record is expired:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>if it is not touched (accessed/read) for <code>max-idle-seconds</code></p>
</li>
<li>
<p><code>time-to-live-seconds</code> passed since it is put to Near Cache.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The actual expiration is performed in the following cases:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>When a record is accessed: it is checked if the record is expired or not.
If it is expired, it is evicted and <code>null</code> is returned as the value to the caller.</p>
</li>
<li>
<p>In the background: there is an expiration task that periodically (currently 5 seconds) scans records and evicts the expired records.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Note that <code>max-idle-seconds</code> and <code>time-to-live-seconds</code> are configured under the <code>near-cache</code> configuration block, as seen in the above
<a href="#near-cache-configuration-examples">configuration examples</a>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_near_cache_invalidation"><a class="anchor" href="#_near_cache_invalidation"></a>Near Cache Invalidation</h3>
<div class="paragraph">
<p>Invalidation is the process of removing an entry from the Near Cache when its value is updated or
it is removed from the original data structure (to prevent stale reads).
Near Cache invalidation happens asynchronously at the cluster level, but synchronously at the current member.
This means that the Near Cache is invalidated within the whole cluster after the modifying operation is finished,
but updated from the current member before the modifying operation is done.
A modifying operation can be an EntryProcessor, an explicit update or remove as well as an expiration or eviction.
Generally, whenever the state of an entry changes in the record store by updating its value or removing it, the invalidation event is sent for that entry.</p>
</div>
<div class="paragraph">
<p>Invalidations can be sent from members to client Near Caches or to member Near Caches, either individually or in batches.
Default behavior is sending in batches. If there are lots of mutating operations such as put/remove on data structures,
it is advised that you configure batch invalidations.
This reduces the network traffic and keeps the eventing system less busy, but may increase the delay of individual invalidations.</p>
</div>
<div class="paragraph">
<p>You can use the following system properties to configure the Near Cache invalidation:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>hazelcast.map.invalidation.batch.enabled</code>: Enable or disable batching.
Its default value is <code>true</code>. When it is set to <code>false</code>, all invalidations are sent immediately.</p>
</li>
<li>
<p><code>hazelcast.map.invalidation.batch.size</code>: Maximum number of invalidations in a batch. Its default value is <code>100</code>.</p>
</li>
<li>
<p><code>hazelcast.map.invalidation.batchfrequency.seconds</code>: If the collected invalidations do not reach the configured batch size,
a background process sends them periodically. Its default value is <code>10</code> seconds.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>If there are a lot of clients or many mutating operations, batching should remain enabled and
the batch size should be configured with the <code>hazelcast.map.invalidation.batch.size</code> system property to a suitable value.</p>
</div>
</div>
<div class="sect2">
<h3 id="_near_cache_consistency"><a class="anchor" href="#_near_cache_consistency"></a>Near Cache Consistency</h3>
<div class="sect3">
<h4 id="_eventual_consistency"><a class="anchor" href="#_eventual_consistency"></a>Eventual Consistency</h4>
<div class="paragraph">
<p>Near Caches are invalidated by invalidation events. Invalidation events can be lost due to the fire-and-forget fashion of eventing system.
If an event is lost, reads from Near Cache can indefinitely be stale.</p>
</div>
<div class="paragraph">
<p>To solve this problem, Hazelcast provides
eventually consistent behavior for IMap/JCache Near Caches by detecting invalidation losses.
After detection of an invalidation loss, stale data is made unreachable and Near Cache&#8217;s <code>get</code> calls to
that data are directed to the underlying IMap/JCache to fetch the fresh data.</p>
</div>
<div class="paragraph">
<p>You can configure eventual consistency with the system properties below (same properties are valid for both member and client side Near Caches):</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>hazelcast.invalidation.max.tolerated.miss.count</code>: Default value is 10.
If missed invalidation count is bigger than this value, relevant cached data is made unreachable.</p>
</li>
<li>
<p><code>hazelcast.invalidation.reconciliation.interval.seconds</code>: Default value is 60 seconds.
This is a periodic task that scans cluster members periodically to compare generated invalidation events with the received ones from Near Cache.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_locally_initiated_changes"><a class="anchor" href="#_locally_initiated_changes"></a>Locally Initiated Changes</h4>
<div class="paragraph">
<p>For local invalidations, when a record is updated/removed, future reads will see this
update/remove to provide read-your-writes consistency. To achieve this consistency, Near Cache configuration provides the following update policies:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>INVALIDATE</code></p>
</li>
<li>
<p><code>CACHE_ON_UPDATE</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>If you choose <code>INVALIDATE</code>, the entry is removed from the Near Cache after the update/remove occurs in
the underlying data structure and before the operation (get) returns to the caller.
Until the update/remove operation completes, the entry&#8217;s old value can still be read from the Near Cache.</p>
</div>
<div class="paragraph">
<p>If you choose <code>CACHE_ON_UPDATE</code>, the entry is updated after the
update/remove occurs in the underlying data structure and before the operation (put/get) returns to the caller.
If it is an update operation, it removes the entry and the new value is placed.
Until the update/remove operation completes, the entry&#8217;s old value can still be read from the Near Cache.
Any threads reading the key after this point read the new entry. If the mutative operation was a remove,
the key will no longer exist in the Near Cache and the original copy in the member.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_near_cache_preloader"><a class="anchor" href="#_near_cache_preloader"></a>Near Cache Preloader</h3>
<div class="paragraph">
<p>The Near Cache preloader is a functionality to store the keys from a Near Cache to provide
a fast re-population of the previous hot data set after a Hazelcast Client has been restarted.
It is available on IMap and JCache clients.</p>
</div>
<div class="paragraph">
<p>The Near Cache preloader stores the keys (not the values) of Near Cache entries in regular intervals.
You can define the initial delay via <code>store-initial-delay-seconds</code>, e.g., if you know that your hot data set needs
some time to build up. You can configure the interval via <code>store-interval-seconds</code> which determines how often
the key-set is stored. The persistence does not run continuously. Whenever the storage is scheduled, it is performed on the actual keys in the Near Cache.</p>
</div>
<div class="paragraph">
<p>The Near Cache preloader is triggered on the first initialization of the data structure on the client, e.g., <code>client.getMap("myNearCacheMap")</code>.
This schedules the preloader, which works in the background, so your application is not blocked.
The storage is enabled after the loading is completed.</p>
</div>
<div class="paragraph">
<p>The configuration parameter <code>directory</code> is optional.
If you omit it, the base folder becomes the user working directory (normally where the JVM was started or
configured with the system property <code>user.dir</code>).
The storage filenames are always created from the Near Cache name.
So even if you use a wildcard name in the Near Cache Configuration, the preloader filenames are unique.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
If you run multiple Hazelcast clients with enabled Near Cache preloader on the same machine,
you have to configure a unique storage filename for each client or run them from different user directories.
If two clients would write into the same file, only the first client succeeds.
The following clients throw an exception as soon as the Near Cache preloader is triggered.
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_caching_deserialized_values"><a class="anchor" href="#_caching_deserialized_values"></a>Caching Deserialized Values</h2>
<div class="sectionbody">
<div class="paragraph">
<p>There may be cases where you do not want to deserialize some values in your Hazelcast map again which were already deserialized previously.
This way your query operations get faster.
This is possible by using the <code>cache-deserialized-values</code> element in your declarative Hazelcast configuration, as shown below.</p>
</div>
<div class="listingblock primary">
<div class="title">XML</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">&lt;hazelcast&gt;
    ...
    &lt;map name="myMap"&gt;
        &lt;in-memory-format&gt;BINARY&lt;/in-memory-format&gt;
        &lt;cache-deserialized-values&gt;INDEX-ONLY&lt;/cache-deserialized-values&gt;
        &lt;backup-count&gt;1&lt;/backup-count&gt;
    &lt;/map&gt;
    ...
&lt;/hazelcast&gt;</code></pre>
</div>
</div>
<div class="listingblock secondary">
<div class="title">YAML</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yml hljs" data-lang="yml">hazelcast:
  map:
    myMap:
      in-memory-format: BINARY
      cache-deserialized-values: INDEX-ONLY
      backup-count: 1</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>cache-deserialized-values</code> element controls the caching of deserialized values.
Note that caching makes the query evaluation faster, but it consumes more memory. This element has the following values:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>NEVER: Deserialized values are never cached.</p>
</li>
<li>
<p>INDEX-ONLY: Deserialized values are cached only when they are inserted into an index.</p>
</li>
<li>
<p>ALWAYS: Deserialized values are always cached.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>If you are using portable serialization or your map&#8217;s in-memory format is <code>OBJECT</code> or <code>NATIVE</code>,
then <code>cache-deserialized-values</code> element does not have any effect.</p>
</div>
<div class="sect2">
<h3 id="_performance_anti_patterns"><a class="anchor" href="#_performance_anti_patterns"></a>Performance Anti Patterns</h3>
<div class="paragraph">
<p>This section covers various recommendations to improve the performance of your Hazelcast IMDG clusters.</p>
</div>
<div class="sect3">
<h4 id="_using_single_member_per_machine"><a class="anchor" href="#_using_single_member_per_machine"></a>Using Single Member per Machine</h4>
<div class="paragraph">
<p>A Hazelcast member assumes it is alone on a machine, so we recommend not running multiple
Hazelcast members on a machine. Having multiple
members on a single machine most likely gives a worse performance compared to
running a single member, since there will be more
context switching, less batching, etc. So unless it is proven that running multiple members per machine does give a better
performance/behavior in your particular setup, it is best to run a single member per machine.</p>
</div>
</div>
<div class="sect3">
<h4 id="_using_operation_threads_efficiently"><a class="anchor" href="#_using_operation_threads_efficiently"></a>Using Operation Threads Efficiently</h4>
<div class="paragraph">
<p>By default, Hazelcast uses the machine&#8217;s core count to determine the number of operation threads. Creating more
operation threads than this core count is highly unlikely leads to an improved performance since there will be more context
switching, more thread notification, etc.</p>
</div>
<div class="paragraph">
<p>Especially if you have a system that does simple operations like put and get,
it is better to use a lower thread count than the number of cores.
The reason behind the increased performance
by reducing the core count is that the operations executed on the operation threads normally execute very fast and there can
be a very significant amount of overhead caused by thread parking and unparking. If there are less threads, a thread needs
to do more work, will block less and therefore needs to be notified less.</p>
</div>
</div>
<div class="sect3">
<h4 id="_avoiding_random_changes"><a class="anchor" href="#_avoiding_random_changes"></a>Avoiding Random Changes</h4>
<div class="paragraph">
<p>Tweaking can be very rewarding because significant performance improvements are possible. By default, Hazelcast tries
to behave at its best for all situations, but this doesn&#8217;t always lead to the best performance. So if you know what
you are doing and what to look for, it can be very rewarding to tweak. However it is also important that tweaking should
be done with proper testing to see if there is actually an improvement. Tweaking without proper benchmarking
is likely going to lead to confusion and could cause all kinds of problems. In case of doubt, we recommend not to tweak.</p>
</div>
</div>
<div class="sect3">
<h4 id="_creating_the_right_benchmark_environment"><a class="anchor" href="#_creating_the_right_benchmark_environment"></a>Creating the Right Benchmark Environment</h4>
<div class="paragraph">
<p>When benchmarking, it is important that the benchmark reflects your production environment. Sometimes with calculated
guess, a representative smaller environment can be set up; but if you want to use the benchmark statistics to inference
how your production system is going to behave, you need to make sure that you get as close as your production setup as
possible. Otherwise, you are at risk of spotting the issues too late or focusing on the things which are not relevant.</p>
</div>
</div>
</div>
</div>
</div>
</article>
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
  </div>
</main>
</div>
<footer class="footer">
  <p>This page was built using the Antora default UI.</p>
  <p>The source code for this UI is licensed under the terms of the MPL-2.0 license.</p>
</footer>
<script src="../../../_/js/site.js"></script>
<link rel="shortcut icon" href="http://hazelcast.com/images/favicon-imdg.png">
<script src="../../../_/js/vendor/lunr.js"></script>
<script src="../../../_/js/vendor/search.js" id="search-script" data-base-path="../../.." data-page-path="/hazelcast/4.1/develop/performance.html"></script>
<script async src="../../../_/../search-index.js"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
